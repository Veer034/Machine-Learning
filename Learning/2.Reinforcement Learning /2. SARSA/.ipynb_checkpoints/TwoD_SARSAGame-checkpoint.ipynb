{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ start\n",
      "           0         1         2          3\n",
      "0   0.000000 -0.007513 -0.035217   0.000000\n",
      "1   0.000000 -0.000048 -1.000000  -0.000078\n",
      "2   0.000000  0.000137 -2.970100  -0.008821\n",
      "6   0.000000  0.000000  0.000000   0.000000\n",
      "5   0.000000  0.000000  0.000000   0.000000\n",
      "3   0.000000  0.000000  0.031642  -0.017741\n",
      "7   0.000000  0.000000  1.020429  -1.990000\n",
      "4  -0.000456 -3.940399 -0.017910   0.000000\n",
      "8   0.000000 -1.990000  0.000000   0.000000\n",
      "9   0.000000  0.000000  0.000000   0.000000\n",
      "12  0.000000 -1.000000  0.000000   0.000000\n",
      "16  0.000000  0.000000  0.000000   0.000000\n",
      "17 -1.000000  0.000000  0.000000   0.000000\n",
      "13  0.000000  0.000000  0.000000   0.000000\n",
      "11  0.008132  0.000000  0.000000  14.854223\n",
      "10  0.000000  0.000000  0.000000   0.000000\n",
      "18  0.000000  0.000000  0.000000   0.000000\n",
      "19  0.000000  0.000000  0.000000   0.000000\n",
      "15  0.017910  0.000000  0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "# This File Consist 2DGames of Maze, dimension can be changes along with goal point an blockage.\n",
    "#Maze class is used for GUI to the SARSA implementation in TwoDQGame class\n",
    "# Author: Ranveer Singh\n",
    "# Learning tutorials: http://mohitmayank.com/reinforcement-learning-with-q-tables/\n",
    "# https://www.youtube.com/watch?v=A5eihauRQvo\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import time\n",
    "import sys\n",
    "if sys.version_info.major == 2:\n",
    "    import Tkinter as tk\n",
    "else:\n",
    "    import tkinter as tk\n",
    "\n",
    "UNIT = 40   # pixels\n",
    "#This class consist of methos for GUI to 2DGame with custom size and blocking dimensions\n",
    "class Maze(tk.Tk, object):\n",
    "    def __init__(self,dim):\n",
    "        super(Maze, self).__init__()\n",
    "        print(\"__init__ start\")\n",
    "        self.title('maze')\n",
    "        self.MAZE_H=dim[0]\n",
    "        self.MAZE_W=dim[1]\n",
    "        self.geometry('{0}x{1}'.format(self.MAZE_H * UNIT, self.MAZE_H * UNIT))\n",
    "        self.origin = np.array([20, 20])      \n",
    "        self._build_maze()\n",
    "        \n",
    "    #Maze Building\n",
    "    def _build_maze(self):\n",
    "        self.canvas = tk.Canvas(self, bg='white',\n",
    "                           height=self.MAZE_H * UNIT,\n",
    "                           width=self.MAZE_W * UNIT)\n",
    "\n",
    "        # create grids\n",
    "        for c in range(0, self.MAZE_W * UNIT, UNIT):\n",
    "            x0, y0, x1, y1 = c, 0, c, self.MAZE_H * UNIT\n",
    "            self.canvas.create_line(x0, y0, x1, y1)\n",
    "        for r in range(0, self.MAZE_H * UNIT, UNIT):\n",
    "            x0, y0, x1, y1 = 0, r, self.MAZE_W * UNIT, r\n",
    "            self.canvas.create_line(x0, y0, x1, y1)     \n",
    "        \n",
    "        # pack all\n",
    "        self.canvas.pack()\n",
    "        \n",
    "    def cellMaker(self,blockage,goal):       \n",
    "        for loss in blockage:\n",
    "            hell1_center = self.origin + np.array([UNIT * loss[1], UNIT*loss[0]])\n",
    "            self.hell1 = self.canvas.create_rectangle(\n",
    "                hell1_center[0] - 15, hell1_center[1] - 15,\n",
    "                hell1_center[0] + 15, hell1_center[1] + 15,\n",
    "                fill='black')\n",
    "        \n",
    "        for win in goal:\n",
    "            oval_center = self.origin + UNIT * 2\n",
    "            self.oval = self.canvas.create_oval(\n",
    "            oval_center[0] - 15, oval_center[1] - 15,\n",
    "            oval_center[0] + 15, oval_center[1] + 15,\n",
    "            fill='yellow')\n",
    "            \n",
    "         # create red rect\n",
    "        self.rect = self.canvas.create_rectangle(\n",
    "            self.origin[0] - 15, self.origin[1] - 15,\n",
    "            self.origin[0] + 15, self.origin[1] + 15,\n",
    "            fill='red')\n",
    "               \n",
    "    # Reset Maze    \n",
    "    def reset(self):\n",
    "        self.update()\n",
    "        time.sleep(0.5)\n",
    "        self.canvas.delete(self.rect)\n",
    "        origin = np.array([20, 20])\n",
    "        self.rect = self.canvas.create_rectangle(\n",
    "            origin[0] - 15, origin[1] - 15,\n",
    "            origin[0] + 15, origin[1] + 15,\n",
    "            fill='red')\n",
    "        # return observation\n",
    "        return self.canvas.coords(self.rect)\n",
    "    \n",
    "    # Steps based on actions passed as argument\n",
    "    def step(self, action):\n",
    "        s = self.canvas.coords(self.rect)\n",
    "        base_action = np.array([0, 0])\n",
    "        if action == 0:   # up\n",
    "            if s[1] > UNIT:\n",
    "                base_action[1] -= UNIT\n",
    "        elif action == 1:   # right\n",
    "            if s[0] < (self.MAZE_W - 1) * UNIT:\n",
    "                base_action[0] += UNIT\n",
    "        elif action == 2:   # down\n",
    "            if s[1] < (self.MAZE_H - 1) * UNIT:\n",
    "                base_action[1] += UNIT\n",
    "        elif action == 3:   # left\n",
    "            if s[0] > UNIT:\n",
    "                base_action[0] -= UNIT\n",
    "\n",
    "        self.canvas.move(self.rect, base_action[0], base_action[1])  # move agent\n",
    "    \n",
    "    # Render the environment\n",
    "    def render(self):\n",
    "        time.sleep(0.1)\n",
    "        self.update()\n",
    "        \n",
    "#This class consist of methods for initial setup of game and configure according tho the passed parameter in\n",
    "#__init__ method. Then consist of methods for creating Q table and changing  value of each co-ordinates based \n",
    "#on the reward received from the action taken.\n",
    "class TwoD_SARSAGame:\n",
    "   \n",
    "     # Core algorithm\n",
    "    gamma = 0.9\n",
    "    alpha = 0.01\n",
    "    n_episodes = 30\n",
    "    epsilon = 0.1\n",
    "    terminal=np.array([])  \n",
    "    random_state = np.random.RandomState(1999)\n",
    "    \n",
    "    #Initializing the env based on passed parameter\n",
    "    def __init__(self, dim, blockage,goal,n_actions,maze):\n",
    "        self.dim = dim\n",
    "        self.n_actions=n_actions\n",
    "        self.blockage = blockage\n",
    "        self.goal = goal\n",
    "        self.maze=maze\n",
    "        self.q_table = pd.DataFrame(columns=list(range(n_actions)),dtype=np.float64)\n",
    "        self._setTable()\n",
    "        \n",
    "    def _setTable(self):\n",
    "        self.gameEnv = [[0 for i in range(self.dim[1])] for j in range(self.dim[0])]\n",
    "        for x in self.blockage:\n",
    "            self.gameEnv[x[0]][x[1]]=-100\n",
    "            self.terminal = np.append(self.terminal, x[0]*dim[1]+x[1])\n",
    "        for x in self.goal:\n",
    "            self.gameEnv[x[0]][x[1]]=100\n",
    "            self.terminal = np.append(self.terminal, x[0]*dim[1]+x[1])\n",
    "            \n",
    "        self.gameEnv=np.array(self.gameEnv)\n",
    "        #print(self.gameEnv)\n",
    "        \n",
    "    \n",
    "    # Action based on action\n",
    "    def actionValidate(self, current_state):\n",
    "        self.check_qTable_directory(current_state)        \n",
    "        data=self.getCoordinate(current_state)   \n",
    "        row=data[0]\n",
    "        column=data[1]\n",
    "        n_actionList = np.full((self.n_actions),-np.inf)\n",
    "        if row > 0 :   # up\n",
    "            n_actionList[0]=self.q_table.loc[current_state,0]\n",
    "        if column < self.dim[1]-1 :   # right\n",
    "            n_actionList[1]=self.q_table.loc[current_state,1]\n",
    "        if row < self.dim[0]-1 :   # down\n",
    "            n_actionList[2]=self.q_table.loc[current_state,2]\n",
    "        if column > 0  :   # left\n",
    "            n_actionList[3]=self.q_table.loc[current_state,3]\n",
    "        return n_actionList\n",
    "                \n",
    "    def getCoordinate(self,state):\n",
    "        row = (int)(state/self.dim[1])\n",
    "        col = (int)(state -(self.dim[1]*row))   \n",
    "        return [row,col]\n",
    "                \n",
    "    def getState(self, row, column):\n",
    "        return self.dim[0]*row+column\n",
    "           \n",
    "    # Next states    \n",
    "    def nextState(self,state,action):\n",
    "        next_state =0\n",
    "        if action ==0 :\n",
    "            next_state= state -self.dim[1] \n",
    "        elif action ==1 :\n",
    "            next_state= state+1 \n",
    "        elif action ==2 :\n",
    "            next_state= state +self.dim[1] \n",
    "        elif action ==3 :\n",
    "            next_state= state-1 \n",
    "        else :\n",
    "            print(\"no proper index.\")\n",
    "        return next_state\n",
    "    \n",
    "    # SARSA logic implemenations\n",
    "    def update_q(self,state, next_state, action,next_action, alpha, gamma):\n",
    "        valid_moves =self.actionValidate(next_state)\n",
    "        self.check_qTable_directory(next_state)           \n",
    "        q_predict = self.q_table.loc[state, action]       \n",
    "        if next_state in self.terminal : \n",
    "            next_state =self.getCoordinate(next_state)\n",
    "            q_target = self.gameEnv[next_state[0],next_state[1]]  \n",
    "        else :\n",
    "            nextActionVal= self.q_table.loc[next_state,next_action]\n",
    "            next_state =self.getCoordinate(next_state)\n",
    "            q_target = self.gameEnv[next_state[0],next_state[1]] + self.gamma * nextActionVal \n",
    "        self.q_table.loc[state, action] += alpha* (q_target - q_predict)  # update\n",
    "    \n",
    "       # Add new co-ordinates to q table        \n",
    "    def check_qTable_directory(self, current_state):\n",
    "        if current_state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(\n",
    "                pd.Series(\n",
    "                    [0]*self.n_actions,\n",
    "                    index=self.q_table.columns,\n",
    "                    name=current_state,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "     # Main method for setting up env, alogorithm and using Maze class to show UI\n",
    "    def main(self):\n",
    "        for e in range(int(self.n_episodes)):\n",
    "            rowHeight = self.dim[0]\n",
    "            columnWidth =self.dim[1]\n",
    "            goal = False\n",
    "            current_state =0\n",
    "            self.maze.reset()\n",
    "            \n",
    "            while not goal:\n",
    "                self.maze.render()\n",
    "                valid_moves =  self.actionValidate(current_state) \n",
    "                # epsilon greedy\n",
    "                if random.random() > self.epsilon:\n",
    "                    actions =np.argwhere(valid_moves == valid_moves.max())                        \n",
    "                else:\n",
    "                    actions=np.argwhere(valid_moves >= -100)     \n",
    "                self.random_state.shuffle(actions)\n",
    "                action=actions[0].item()\n",
    "                next_state= self.nextState(current_state,action)    \n",
    "                \n",
    "                valid_moves =  self.actionValidate(next_state) \n",
    "                if random.random() > self.epsilon:\n",
    "                    actions =np.argwhere(valid_moves == valid_moves.max())                        \n",
    "                else:\n",
    "                    actions=np.argwhere(valid_moves >= -100)     \n",
    "                                                     \n",
    "                self.random_state.shuffle(actions)             \n",
    "                next_action=actions[0].item()\n",
    "                self.maze.step(action)    \n",
    "                self.update_q(current_state, next_state, action,next_action,\n",
    "                                  alpha=self.alpha, gamma=self.gamma)\n",
    "                \n",
    "                # Goal state has reward 100\n",
    "                if next_state in self.terminal :       \n",
    "                    goal = True\n",
    "                current_state = next_state\n",
    "                \n",
    "        print(self.q_table)\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    dim =np.array([5,4], dtype=int)\n",
    "    block =[[1,2],[2,1],[3,1],[1,1]]\n",
    "    goal =[[2,2]]\n",
    "    n_actions = 4\n",
    "    maze = Maze(dim)\n",
    "    maze.cellMaker(block,goal)\n",
    "    game = TwoD_SARSAGame(dim,block,goal,n_actions,maze)\n",
    "    game.main()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
